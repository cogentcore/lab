// Code generated by "goal build"; DO NOT EDIT.
//
//line basic.goal:1
package test

import (
	"math"

	"cogentcore.org/core/math32"
	"cogentcore.org/lab/gosl/slbool"
	"cogentcore.org/lab/tensor"
)

//gosl:start

//gosl:vars
var (
	// Params are the parameters for the computation.
	//
	//gosl:read-only
	Params []ParamStruct

	// Ctx provides additional context, and is usually read-only,
	// but is updated in a specific kernel flagged as read-write.
	//
	//gosl:read-or-write
	Ctx []Context

	// Data is the data on which the computation operates.
	// 2D: outer index is data, inner index is: Raw, Integ, Exp vars.
	//
	//gosl:group Data
	//gosl:dims 2
	Data *tensor.Float32
)

const (
	Raw int = iota
	Integ
	Exp
	NVars
)

// FastExp is a quartic spline approximation to the Exp function, by N.N. Schraudolph
// It does not have any of the sanity checking of a standard method -- returns
// nonsense when arg is out of range.  Runs in 2.23ns vs. 6.3ns for 64bit which is faster
// than math32.Exp actually.
func FastExp(x float32) float32 {
	if x <= -88.76731 { // this doesn't add anything and -exp is main use-case anyway
		return 0
	}
	i := int32(12102203*x) + int32(127)*(int32(1)<<23)
	m := i >> 7 & 0xFFFF // copy mantissa
	i += (((((((((((3537 * m) >> 16) + 13668) * m) >> 18) + 15817) * m) >> 14) - 80470) * m) >> 11)
	return math.Float32frombits(uint32(i))
}

// NeuronFlags are bit-flags encoding relevant binary state for neurons
type NeuronFlags int32

// The neuron flags
const (
	// NeuronOff flag indicates that this neuron has been turned off (i.e., lesioned)
	NeuronOff NeuronFlags = 0x01

	// NeuronHasExt means the neuron has external input in its Ext field
	NeuronHasExt NeuronFlags = 0x02 // note: 1<<2 does NOT work

	// NeuronHasTarg means the neuron has external target input in its Target field
	NeuronHasTarg NeuronFlags = 0x04

	// NeuronHasCmpr means the neuron has external comparison input in its Target field -- used for computing
	// comparison statistics but does not drive neural activity ever
	NeuronHasCmpr NeuronFlags = 0x08
)

// Modes are evaluation modes (Training, Testing, etc)
type Modes int32

// The evaluation modes
const (
	NoEvalMode Modes = iota

	// AllModes indicates that the log should occur over all modes present in other items.
	AllModes

	// Train is this a training mode for the env
	Train

	// Test is this a test mode for the env
	Test
)

// testSlice is a global array: will be const = array(...);
var testSlice = [Test + 1]Modes{NoEvalMode, AllModes, Train, Test}

// SubParamStruct has the test sub-params
type SubParamStruct struct {
	A, B, C, D float32
}

func (sp *SubParamStruct) Sum() float32 {
	return sp.A + sp.B + sp.C + sp.D
}

func (sp *SubParamStruct) SumPlus(extra float32) float32 {
	return sp.Sum() + extra
}

// ParamStruct has the test params
type ParamStruct struct {

	// rate constant in msec
	Tau float32

	// 1/Tau
	Dt     float32
	Option slbool.Bool // note: standard bool doesn't work

	pad float32 // comment this out to trigger alignment warning

	// extra parameters
	Subs SubParamStruct
}

func (ps *ParamStruct) IntegFromRaw(idx int) float32 {
	// note: the following are just to test basic control structures
	integ := Data.Value(int(idx), int(Integ))
	newVal := ps.Dt * (Data.Value(int(idx), int(Raw)) - integ)
	if newVal < -10 || ps.Option.IsTrue() {
		newVal = -10
	}
	integ += newVal
	Data.Set(integ, int(idx), int(Integ))
	Data.Set(math32.Exp(-integ), int(idx), int(Exp))
	var a float32
	ctx := GetCtx(0)
	ps.AnotherMeth(ctx, idx, &a)
	return Data.Value(int(idx), int(Exp))
}

// AnotherMeth does more computation.
// ctx arg must be converted to non-pointer.
func (ps *ParamStruct) AnotherMeth(ctx *Context, idx int, ptrarg *float32) {
	for i := 0; i < 10; i++ {
		Data.SetMul(0.99, int(idx), int(Integ))
	}
	var flag NeuronFlags
	flag &^= NeuronHasExt // clear flag -- op doesn't exist in C

	mode := Test
	switch mode { // note: no fallthrough!
	case Test:
		ab := float32(42)
		Data.SetDiv(ab, int(idx), int(Exp))
	case Train:
		ab := float32(.5)
		Data.SetMul(ab, int(idx), int(Exp))
	default:
		ab := float32(1)
		Data.SetMul(ab, int(idx), int(Exp))
	}

	var a, b float32
	b = 42
	a = ps.Subs.Sum()
	Data.Set(ps.Subs.SumPlus(b), int(idx), int(Exp))
	Data.Set(a, int(idx), int(Integ))

	for i := range 10 {
		_ = i
		Data.SetMul(0.99, int(idx), int(Exp))
	}

	*ptrarg = -1
}

// Context struct
type Context struct {
	Cycles float32
	Index  uint32
	Option slbool.Bool
	pad    float32 // comment this out to trigger alignment warning
}

// UpdtCycle does cycle updating
//
//gosl:pointer-receiver
func (ctx *Context) UpdtCycle() {
	ctx.Cycles += 1
	ctx.Index = 42
}

//gosl:end

// note: only core compute code needs to be in shader -- all init is done CPU-side

func (ps *ParamStruct) Defaults() {
	ps.Tau = 5
	ps.Update()
}

func (ps *ParamStruct) Update() {
	ps.Dt = 1.0 / ps.Tau
}

func (ps *ParamStruct) String() string {
	return "params!"
}

//gosl:start

// Compute does the main computation
func Compute(i uint32) { //gosl:kernel
	params := GetParams(0)
	params.IntegFromRaw(int(i))
}

// Compute does the main computation
func CycleUpdt(i uint32) { //gosl:kernel read-write:Ctx
	ctx := GetCtx(0)
	ctx.UpdtCycle()
}

//gosl:end
