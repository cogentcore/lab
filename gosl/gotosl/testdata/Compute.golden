// Code generated by "gosl"; DO NOT EDIT
// kernel: Compute

// // Params are the parameters for the computation. // 
@group(0) @binding(0)
var<storage, read> TensorStrides: array<u32>;
@group(0) @binding(1)
var<storage, read> Params: array<ParamStruct>;
@group(0) @binding(2)
var<storage, read_write> Ctx: array<Context>;
// // Data is the data on which the computation operates. // 2D: outer index is data, inner index is: Raw, Integ, Exp vars. // 
@group(1) @binding(0)
var<storage, read_write> Data: array<f32>;
@group(1) @binding(1)
var<storage, read_write> Big0: array<f32>;
@group(1) @binding(2)
var<storage, read_write> Big1: array<f32>;
@group(1) @binding(3)
var<storage, read_write> Big2: array<f32>;

alias GPUVars = i32;

@compute @workgroup_size(64, 1, 1)
fn main(@builtin(workgroup_id) wgid: vec3<u32>, @builtin(num_workgroups) nwg: vec3<u32>, @builtin(local_invocation_index) loci: u32) {
	let idx = loci + (wgid.x + wgid.y * nwg.x + wgid.z * nwg.x * nwg.y) * 64;
	Compute(idx);
}

fn Index2D(s0: u32, s1: u32, i0: u32, i1: u32) -> u32 {
	return s0 * i0 + s1 * i1;
}

fn BigGet(ix: u32) -> f32 {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		return Big0[ix];
	}
	case u32(1): {
		return Big1[ix - 536870904];
	}
	default: {
		return Big2[ix - 1073741808];
	}
	}
}

fn BigSet(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		Big0[ix] = vl;
	}
	case u32(1): {
		Big1[ix - 536870904] = vl;
	}
	default: {
		Big2[ix - 1073741808] = vl;
	}
	}
}

fn BigSetAdd(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		Big0[ix] += vl;
	}
	case u32(1): {
		Big1[ix - 536870904] += vl;
	}
	default: {
		Big2[ix - 1073741808] += vl;
	}
	}
}

fn BigSetSub(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		Big0[ix] -= vl;
	}
	case u32(1): {
		Big1[ix - 536870904] -= vl;
	}
	default: {
		Big2[ix - 1073741808] -= vl;
	}
	}
}

fn BigSetMul(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		Big0[ix] *= vl;
	}
	case u32(1): {
		Big1[ix - 536870904] *= vl;
	}
	default: {
		Big2[ix - 1073741808] *= vl;
	}
	}
}

fn BigSetDiv(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		Big0[ix] /= vl;
	}
	case u32(1): {
		Big1[ix - 536870904] /= vl;
	}
	default: {
		Big2[ix - 1073741808] /= vl;
	}
	}
}


//////// import: "basic.go"
const  Raw: i32   = 0;
const  Integ: i32 = 1;
const  Exp: i32 = 2;
const  NVars: i32 = 3;
alias NeuronFlags = i32;
const  NeuronOff: NeuronFlags = 0x01;
const  NeuronHasExt: NeuronFlags = 0x02; // note: 1<<2 does NOT work
const  NeuronHasTarg: NeuronFlags = 0x04;
const  NeuronHasCmpr: NeuronFlags = 0x08;
alias Modes = i32;
const  NoEvalMode: Modes = 0;
const  AllModes: Modes = 1;
const  Train: Modes = 2;
const  Test: Modes = 3;
const testSlice = array(NoEvalMode, AllModes, Train, Test);
struct SubParamStruct {
	A: f32,
	B: f32,
	C: f32,
	D: f32,
}
fn SubParamStruct_Sum(sp: SubParamStruct) -> f32 {
	return sp.A + sp.B + sp.C + sp.D;
}
fn SubParamStruct_SumPlus(sp: SubParamStruct, extra: f32) -> f32 {
	return SubParamStruct_Sum(sp) + extra;
}
struct ParamStruct {
	Tau: f32,
	Dt:     f32,
	Option: i32, // note: standard bool doesn't work
	pad: f32, // comment this out to trigger alignment warning
	VXYf: vec4<f32>,  // translates to vec4<f32>
	VXYi: vec4<i32>, // translates to vec4<i32>
	Subs: SubParamStruct,
}
fn ParamStruct_IntegFromRaw(ps: ParamStruct, idx: i32) -> f32 {
	var integ = Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Integ))];
	var newVal = ps.Dt * (Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Raw))] - integ);
	if (newVal < -10 || ps.Option == 1) {
		newVal = f32(-10);
	}
	integ += newVal;
	Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Integ))] = integ;
	Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Exp))] = exp(-integ);
	var a = ps.VXYf.x;
	let ctx = Ctx[0];
	ParamStruct_AnotherMeth(ps, ctx, idx, &a);
	var bv = BigGet(Index2D(TensorStrides[10], TensorStrides[11], u32(idx), u32(Integ)));
	BigSet(bv * 2, Index2D(TensorStrides[10], TensorStrides[11], u32(idx), u32(Exp)));return Data[Index2D(TensorStrides[0], TensorStrides[1],
u32(idx), u32(Exp))];
}
fn ParamStruct_AnotherMeth(ps: ParamStruct, ctx: Context, idx: i32, ptrarg: ptr<function,f32>) {
	for (var i = 0; i < 10; i++) {
		Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Integ))] *= 0.99;
	}
	var flag: NeuronFlags;
	flag &= ~NeuronHasExt; // clear flag -- op doesn't exist in C
	var mode = Test;
	switch (mode) { // note: no fallthrough!
	case Test: {
		var ab = f32(42);
		Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Exp))] /= ab;
	}
	case Train: {
		var ab = f32(.5);
		Data[Index2D(TensorStrides[0], TensorStrides[1],
		u32(idx), u32(Exp))] *= ab;
	}
	default: {
		var ab = f32(1);
		Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Exp))] *= ab;
	}
	}
	var a: f32;
	var b: f32;
	b = f32(42);
	a = SubParamStruct_Sum(ps.Subs);
	Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Exp))] = SubParamStruct_SumPlus(ps.Subs, b);
	Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Integ))] = a;
	for (var i=0; i<10; i++) {
		_ = i;
		Data[Index2D(TensorStrides[0], TensorStrides[1], u32(idx), u32(Exp))] *= 0.99;
	}
	*ptrarg = f32(-1);
}
struct Context {
	Cycles: f32,
	Index:  u32,
	Option: i32,
	pad:    f32, // comment this out to trigger alignment warning
}
fn Compute(i: u32) { //gosl:kernel
	let params = Params[0];
	ParamStruct_IntegFromRaw(params, i32(i));
}