// Code generated by "gosl"; DO NOT EDIT

package test

import (
	"embed"
	"unsafe"
	"cogentcore.org/core/gpu"
	"cogentcore.org/lab/tensor"
)

//go:embed shaders/*.wgsl
var shaders embed.FS

// ComputeGPU is the compute gpu device
var ComputeGPU *gpu.GPU

// UseGPU indicates whether to use GPU vs. CPU.
var UseGPU bool

// GPUSystem is a GPU compute System with kernels operating on the
// same set of data variables.
var GPUSystem *gpu.ComputeSystem

// GPUVars is an enum for GPU variables, for specifying what to sync.
type GPUVars int32 //enums:enum

const (
	ParamsVar GPUVars = 0
	CtxVar GPUVars = 1
	DataVar GPUVars = 2
)

// Tensor stride variables
var TensorStrides tensor.Uint32

// GPUInit initializes the GPU compute system,
// configuring system(s), variables and kernels.
// It is safe to call multiple times: detects if already run.
func GPUInit() {
	if ComputeGPU != nil {
		return
	}
	gp := gpu.NewComputeGPU()
	ComputeGPU = gp
	{
		sy := gpu.NewComputeSystem(gp, "Default")
		GPUSystem = sy
		gpu.NewComputePipelineShaderFS(shaders, "shaders/Compute.wgsl", sy)
		gpu.NewComputePipelineShaderFS(shaders, "shaders/CycleUpdt.wgsl", sy)
		vars := sy.Vars()
		{
			sgp := vars.AddGroup(gpu.Storage, "Group_0")
			var vr *gpu.Var
			_ = vr
			vr = sgp.Add("TensorStrides", gpu.Uint32, 1, gpu.ComputeShader)
			vr.ReadOnly = true
			vr = sgp.AddStruct("Params", int(unsafe.Sizeof(ParamStruct{})), 1, gpu.ComputeShader)
			vr.ReadOnly = true
			vr = sgp.AddStruct("Ctx", int(unsafe.Sizeof(Context{})), 1, gpu.ComputeShader)
			sgp.SetNValues(1)
		}
		{
			sgp := vars.AddGroup(gpu.Storage, "Data")
			var vr *gpu.Var
			_ = vr
			vr = sgp.Add("Data", gpu.Float32, 1, gpu.ComputeShader)
			sgp.SetNValues(1)
		}
		sy.Config()
	}
}

// GPURelease releases the GPU compute system resources.
// Call this at program exit.
func GPURelease() {
	if GPUSystem != nil {
		GPUSystem.Release()
		GPUSystem = nil
	}

	if ComputeGPU != nil {
		ComputeGPU.Release()
		ComputeGPU = nil
	}
}

// RunCompute runs the Compute kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// Can call multiple Run* kernels in a row, which are then all launched
// in the same command submission on the GPU, which is by far the most efficient.
// MUST call RunDone (with optional vars to sync) after all Run calls.
// Alternatively, a single-shot RunOneCompute call does Run and Done for a
// single run-and-sync case.
func RunCompute(n int) {
	if UseGPU {
		RunComputeGPU(n)
	} else {
		RunComputeCPU(n)
	}
}

// RunComputeGPU runs the Compute kernel on the GPU. See [RunCompute] for more info.
func RunComputeGPU(n int) {
	sy := GPUSystem
	pl := sy.ComputePipelines["Compute"]
	ce, _ := sy.BeginComputePass()
	pl.Dispatch1D(ce, n, 64)
}

// RunComputeCPU runs the Compute kernel on the CPU.
func RunComputeCPU(n int) {
	gpu.VectorizeFunc(0, n, Compute)
}

// RunOneCompute runs the Compute kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// This version then calls RunDone with the given variables to sync
// after the Run, for a single-shot Run-and-Done call. If multiple kernels
// can be run in sequence, it is much more efficient to do multiple Run*
// calls followed by a RunDone call.
func RunOneCompute(n int, syncVars ...GPUVars) {
	if UseGPU {
		RunComputeGPU(n)
		RunDone(syncVars...)
	} else {
		RunComputeCPU(n)
	}
}
// RunCycleUpdt runs the CycleUpdt kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// Can call multiple Run* kernels in a row, which are then all launched
// in the same command submission on the GPU, which is by far the most efficient.
// MUST call RunDone (with optional vars to sync) after all Run calls.
// Alternatively, a single-shot RunOneCycleUpdt call does Run and Done for a
// single run-and-sync case.
func RunCycleUpdt(n int) {
	if UseGPU {
		RunCycleUpdtGPU(n)
	} else {
		RunCycleUpdtCPU(n)
	}
}

// RunCycleUpdtGPU runs the CycleUpdt kernel on the GPU. See [RunCycleUpdt] for more info.
func RunCycleUpdtGPU(n int) {
	sy := GPUSystem
	pl := sy.ComputePipelines["CycleUpdt"]
	ce, _ := sy.BeginComputePass()
	pl.Dispatch1D(ce, n, 64)
}

// RunCycleUpdtCPU runs the CycleUpdt kernel on the CPU.
func RunCycleUpdtCPU(n int) {
	gpu.VectorizeFunc(0, n, CycleUpdt)
}

// RunOneCycleUpdt runs the CycleUpdt kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// This version then calls RunDone with the given variables to sync
// after the Run, for a single-shot Run-and-Done call. If multiple kernels
// can be run in sequence, it is much more efficient to do multiple Run*
// calls followed by a RunDone call.
func RunOneCycleUpdt(n int, syncVars ...GPUVars) {
	if UseGPU {
		RunCycleUpdtGPU(n)
		RunDone(syncVars...)
	} else {
		RunCycleUpdtCPU(n)
	}
}
// RunDone must be called after Run* calls to start compute kernels.
// This actually submits the kernel jobs to the GPU, and adds commands
// to synchronize the given variables back from the GPU to the CPU.
// After this function completes, the GPU results will be available in 
// the specified variables.
func RunDone(syncVars ...GPUVars) {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	sy.ComputeEncoder.End()
	ReadFromGPU(syncVars...)
	sy.EndComputePass()
	SyncFromGPU(syncVars...)
}

// ToGPU copies given variables to the GPU for the system.
func ToGPU(vars ...GPUVars) {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			gpu.SetValueFrom(v, Params)
		case CtxVar:
			v, _ := syVars.ValueByIndex(0, "Ctx", 0)
			gpu.SetValueFrom(v, Ctx)
		case DataVar:
			v, _ := syVars.ValueByIndex(1, "Data", 0)
			gpu.SetValueFrom(v, Data.Values)
		}
	}
}
// RunGPUSync can be called to synchronize data between CPU and GPU.
// Any prior ToGPU* calls will execute to send data to the GPU,
// and any subsequent RunDone* calls will copy data back from the GPU.
func RunGPUSync() {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	sy.BeginComputePass()
}

// ToGPUTensorStrides gets tensor strides and starts copying to the GPU.
func ToGPUTensorStrides() {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	syVars := sy.Vars()
	TensorStrides.SetShapeSizes(10)
	TensorStrides.SetInt1D(Data.Shape().Strides[0], 0)
	TensorStrides.SetInt1D(Data.Shape().Strides[1], 1)
	v, _ := syVars.ValueByIndex(0, "TensorStrides", 0)
	gpu.SetValueFrom(v, TensorStrides.Values)
}

// ReadFromGPU starts the process of copying vars to the GPU.
func ReadFromGPU(vars ...GPUVars) {
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			v.GPUToRead(sy.CommandEncoder)
		case CtxVar:
			v, _ := syVars.ValueByIndex(0, "Ctx", 0)
			v.GPUToRead(sy.CommandEncoder)
		case DataVar:
			v, _ := syVars.ValueByIndex(1, "Data", 0)
			v.GPUToRead(sy.CommandEncoder)
		}
	}
}

// SyncFromGPU synchronizes vars from the GPU to the actual variable.
func SyncFromGPU(vars ...GPUVars) {
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			v.ReadSync()
			gpu.ReadToBytes(v, Params)
		case CtxVar:
			v, _ := syVars.ValueByIndex(0, "Ctx", 0)
			v.ReadSync()
			gpu.ReadToBytes(v, Ctx)
		case DataVar:
			v, _ := syVars.ValueByIndex(1, "Data", 0)
			v.ReadSync()
			gpu.ReadToBytes(v, Data.Values)
		}
	}
}

// GetParams returns a pointer to the given global variable: 
// [Params] []ParamStruct at given index. This directly processed in the GPU code,
// so this function call is an equivalent for the CPU.
func GetParams(idx uint32) *ParamStruct {
	return &Params[idx]
}

// GetCtx returns a pointer to the given global variable: 
// [Ctx] []Context at given index. This directly processed in the GPU code,
// so this function call is an equivalent for the CPU.
func GetCtx(idx uint32) *Context {
	return &Ctx[idx]
}
