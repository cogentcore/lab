// Code generated by "gosl"; DO NOT EDIT

package main

import (
	"embed"
	"fmt"
	"math"
	"unsafe"
	"cogentcore.org/core/gpu"
	"cogentcore.org/lab/tensor"
)

//go:embed shaders/*.wgsl
var shaders embed.FS

var (
	// GPUInitialized is true once the GPU system has been initialized.
	// Prevents multiple initializations.
	GPUInitialized bool
	
	// ComputeGPU is the compute gpu device.
	// Set this prior to calling GPUInit() to use an existing device.
	ComputeGPU *gpu.GPU

	// BorrowedGPU is true if our ComputeGPU is set externally,
	// versus created specifically for this system. If external,
	// we don't release it.
	BorrowedGPU bool
	
	// UseGPU indicates whether to use GPU vs. CPU.
	UseGPU bool
)
// GPUSystem is a GPU compute System with kernels operating on the
// same set of data variables.
var GPUSystem *gpu.ComputeSystem

// GPUVars is an enum for GPU variables, for specifying what to sync.
type GPUVars int32 //enums:enum

const (
	ParamsVar GPUVars = 0
	DataVar GPUVars = 1
	IntDataVar GPUVars = 2
)

// Tensor stride variables
var TensorStrides tensor.Uint32

// GPUInit initializes the GPU compute system,
// configuring system(s), variables and kernels.
// It is safe to call multiple times: detects if already run.
func GPUInit() {
	if GPUInitialized {
		return
	}
	GPUInitialized = true
	if ComputeGPU == nil { // set prior to this call to use an external
		ComputeGPU = gpu.NewComputeGPU()
	} else {
		BorrowedGPU = true
	}
	gp := ComputeGPU
	
	_ = fmt.Sprintf("%g",math.NaN()) // keep imports happy
	{
		sy := gpu.NewComputeSystem(gp, "Default")
		GPUSystem = sy
		vars := sy.Vars()
		{
			sgp := vars.AddGroup(gpu.Storage, "Params")
			var vr *gpu.Var
			_ = vr
			vr = sgp.Add("TensorStrides", gpu.Uint32, 1, gpu.ComputeShader)
			vr.ReadOnly = true
			vr = sgp.AddStruct("Params", int(unsafe.Sizeof(ParamStruct{})), 1, gpu.ComputeShader)
			vr.ReadOnly = true
			sgp.SetNValues(1)
		}
		{
			sgp := vars.AddGroup(gpu.Storage, "Data")
			var vr *gpu.Var
			_ = vr
			vr = sgp.Add("Data0", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data1", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data2", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data3", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data4", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data5", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data6", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("Data7", gpu.Float32, 1, gpu.ComputeShader)
			vr = sgp.Add("IntData", gpu.Int32, 1, gpu.ComputeShader)
			sgp.SetNValues(1)
		}
		var pl *gpu.ComputePipeline
		pl = gpu.NewComputePipelineShaderFS(shaders, "shaders/Atomic.wgsl", sy)
		pl.AddVarUsed(0, "TensorStrides")
		pl.AddVarUsed(1, "IntData")
		pl = gpu.NewComputePipelineShaderFS(shaders, "shaders/Compute.wgsl", sy)
		pl.AddVarUsed(0, "TensorStrides")
		pl.AddVarUsed(1, "Data0")
		pl.AddVarUsed(1, "Data1")
		pl.AddVarUsed(1, "Data2")
		pl.AddVarUsed(1, "Data3")
		pl.AddVarUsed(1, "Data4")
		pl.AddVarUsed(1, "Data5")
		pl.AddVarUsed(1, "Data6")
		pl.AddVarUsed(1, "Data7")
		pl.AddVarUsed(0, "Params")
		sy.Config()
	}
}

// GPURelease releases the GPU compute system resources.
// Call this at program exit.
func GPURelease() {
	if GPUSystem != nil {
		GPUSystem.Release()
		GPUSystem = nil
	}

	if !BorrowedGPU && ComputeGPU != nil {
		ComputeGPU.Release()
	
	}
	ComputeGPU = nil
}

// RunAtomic runs the Atomic kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// Can call multiple Run* kernels in a row, which are then all launched
// in the same command submission on the GPU, which is by far the most efficient.
// MUST call RunDone (with optional vars to sync) after all Run calls.
// Alternatively, a single-shot RunOneAtomic call does Run and Done for a
// single run-and-sync case.
func RunAtomic(n int) {
	if UseGPU {
		RunAtomicGPU(n)
	} else {
		RunAtomicCPU(n)
	}
}

// RunAtomicGPU runs the Atomic kernel on the GPU. See [RunAtomic] for more info.
func RunAtomicGPU(n int) {
	sy := GPUSystem
	pl := sy.ComputePipelines["Atomic"]
	ce, _ := sy.BeginComputePass()
	pl.Dispatch1D(ce, n, 64)
}

// RunAtomicCPU runs the Atomic kernel on the CPU.
func RunAtomicCPU(n int) {
	gpu.VectorizeFunc(0, n, Atomic)
}

// RunOneAtomic runs the Atomic kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// This version then calls RunDone with the given variables to sync
// after the Run, for a single-shot Run-and-Done call. If multiple kernels
// can be run in sequence, it is much more efficient to do multiple Run*
// calls followed by a RunDone call.
func RunOneAtomic(n int, syncVars ...GPUVars) {
	if UseGPU {
		RunAtomicGPU(n)
		RunDone(syncVars...)
	} else {
		RunAtomicCPU(n)
	}
}
// RunCompute runs the Compute kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// Can call multiple Run* kernels in a row, which are then all launched
// in the same command submission on the GPU, which is by far the most efficient.
// MUST call RunDone (with optional vars to sync) after all Run calls.
// Alternatively, a single-shot RunOneCompute call does Run and Done for a
// single run-and-sync case.
func RunCompute(n int) {
	if UseGPU {
		RunComputeGPU(n)
	} else {
		RunComputeCPU(n)
	}
}

// RunComputeGPU runs the Compute kernel on the GPU. See [RunCompute] for more info.
func RunComputeGPU(n int) {
	sy := GPUSystem
	pl := sy.ComputePipelines["Compute"]
	ce, _ := sy.BeginComputePass()
	pl.Dispatch1D(ce, n, 64)
}

// RunComputeCPU runs the Compute kernel on the CPU.
func RunComputeCPU(n int) {
	gpu.VectorizeFunc(0, n, Compute)
}

// RunOneCompute runs the Compute kernel with given number of elements,
// on either the CPU or GPU depending on the UseGPU variable.
// This version then calls RunDone with the given variables to sync
// after the Run, for a single-shot Run-and-Done call. If multiple kernels
// can be run in sequence, it is much more efficient to do multiple Run*
// calls followed by a RunDone call.
func RunOneCompute(n int, syncVars ...GPUVars) {
	if UseGPU {
		RunComputeGPU(n)
		RunDone(syncVars...)
	} else {
		RunComputeCPU(n)
	}
}
// RunDone must be called after Run* calls to start compute kernels.
// This actually submits the kernel jobs to the GPU, and adds commands
// to synchronize the given variables back from the GPU to the CPU.
// After this function completes, the GPU results will be available in 
// the specified variables.
func RunDone(syncVars ...GPUVars) {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	sy.ComputeEncoder.End()
	ReadFromGPU(syncVars...)
	sy.EndComputePass()
	SyncFromGPU(syncVars...)
}

// ToGPU copies given variables to the GPU for the system.
func ToGPU(vars ...GPUVars) {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			gpu.SetValueFrom(v, Params)
		case DataVar:
			bsz := 536870904
			n := Data.Len()
			nb := int(math.Ceil(float64(n) / float64(bsz)))
			for bi := range nb {
				v, _ := syVars.ValueByIndex(1, fmt.Sprintf("Data%d", bi), 0)
				st := bsz * bi
				ed := min(bsz * (bi+1), n)
				gpu.SetValueFrom(v, Data.Values[st:ed])
			}
		case IntDataVar:
			v, _ := syVars.ValueByIndex(1, "IntData", 0)
			gpu.SetValueFrom(v, IntData.Values)
		}
	}
}
// RunGPUSync can be called to synchronize data between CPU and GPU.
// Any prior ToGPU* calls will execute to send data to the GPU,
// and any subsequent RunDone* calls will copy data back from the GPU.
func RunGPUSync() {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	sy.BeginComputePass()
}

// ToGPUTensorStrides gets tensor strides and starts copying to the GPU.
func ToGPUTensorStrides() {
	if !UseGPU {
		return
	}
	sy := GPUSystem
	syVars := sy.Vars()
	TensorStrides.SetShapeSizes(20)
	TensorStrides.SetInt1D(Data.Shape().Strides[0], 0)
	TensorStrides.SetInt1D(Data.Shape().Strides[1], 1)
	TensorStrides.SetInt1D(IntData.Shape().Strides[0], 10)
	TensorStrides.SetInt1D(IntData.Shape().Strides[1], 11)
	v, _ := syVars.ValueByIndex(0, "TensorStrides", 0)
	gpu.SetValueFrom(v, TensorStrides.Values)
}

// ReadFromGPU starts the process of copying vars to the GPU.
func ReadFromGPU(vars ...GPUVars) {
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			v.GPUToRead(sy.CommandEncoder)
		case DataVar:
			bsz := 536870904
			n := Data.Len()
			nb := int(math.Ceil(float64(n) / float64(bsz)))
			for bi := range nb {
				v, _ := syVars.ValueByIndex(1, fmt.Sprintf("Data%d", bi), 0)
				v.GPUToRead(sy.CommandEncoder)
			}
		case IntDataVar:
			v, _ := syVars.ValueByIndex(1, "IntData", 0)
			v.GPUToRead(sy.CommandEncoder)
		}
	}
}

// SyncFromGPU synchronizes vars from the GPU to the actual variable.
func SyncFromGPU(vars ...GPUVars) {
	sy := GPUSystem
	syVars := sy.Vars()
	for _, vr := range vars {
		switch vr {
		case ParamsVar:
			v, _ := syVars.ValueByIndex(0, "Params", 0)
			v.ReadSync()
			gpu.ReadToBytes(v, Params)
		case DataVar:
			bsz := 536870904
			n := Data.Len()
			nb := int(math.Ceil(float64(n) / float64(bsz)))
			for bi := range nb {
				v, _ := syVars.ValueByIndex(1, fmt.Sprintf("Data%d", bi), 0)
				v.ReadSync()
				st := bsz * bi
				ed := min(bsz * (bi+1), n)
				gpu.ReadToBytes(v, Data.Values[st:ed])
			}
		case IntDataVar:
			v, _ := syVars.ValueByIndex(1, "IntData", 0)
			v.ReadSync()
			gpu.ReadToBytes(v, IntData.Values)
		}
	}
}

// GetParams returns a pointer to the given global variable: 
// [Params] []ParamStruct at given index. This directly processed in the GPU code,
// so this function call is an equivalent for the CPU.
func GetParams(idx uint32) *ParamStruct {
	return &Params[idx]
}
